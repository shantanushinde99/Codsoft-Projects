import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# Load and preprocess the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalize the images to [0,1] and reshape for CNN input
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
x_train = x_train[..., tf.newaxis]  # Shape: (60000, 28, 28, 1)
x_test = x_test[..., tf.newaxis]    # Shape: (10000, 28, 28, 1)

# Define the CNN model architecture
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile the model with accuracy as a metric
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model and store training history
history = model.fit(x_train, y_train, epochs=5,
                    validation_data=(x_test, y_test))

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)
print(f'\nTest accuracy: {test_accuracy:.4f}')
print(f'Test loss: {test_loss:.4f}')

# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()



This Python code demonstrates the use of a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset, a standard benchmark in image recognition. The dataset consists of grayscale images (28x28 pixels) of digits (0–9). The images are normalized by scaling pixel values to the range [0, 1] and reshaped to include a channel dimension, preparing them for convolutional layers.

The CNN architecture includes two convolutional layers: the first with 32 filters and the second with 64, both using 3×3 kernels and ReLU activation for non-linearity. Each convolution layer is followed by a MaxPooling layer that reduces spatial dimensions and helps extract dominant features. The output is flattened and passed through a dense layer with 64 neurons, and finally through a softmax layer with 10 outputs, representing the digit classes. The model is compiled using the Adam optimizer and sparse_categorical_crossentropy loss, appropriate for integer-labeled multi-class classification.

The model is trained for 5 epochs using both training and validation data. After training, the model is evaluated on the test set to report accuracy and loss. Accuracy and loss graphs for both training and validation sets are plotted to visually analyze learning behavior. This example showcases how CNNs efficiently extract spatial features and patterns in image data, making them ideal for digit recognition tasks like MNIST.